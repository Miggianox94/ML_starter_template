{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project name - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem definition\n",
    "> Insert here your problem description\n",
    "\n",
    "## Data\n",
    "Explain the dataset, how all files are composed and the description of each column\n",
    "\n",
    "## Evaluation\n",
    "Explain the evaluation metric that you want to use to evaluate the model. Specify the goal in terms of evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What will be covered\n",
    "1. Import of common libraries\n",
    "2. Data ingestion & cleaning\n",
    "3. Data Analysis and visualization\n",
    "4. Feature Selection\n",
    "5. ML model selection\n",
    "6. ML model tuning\n",
    "7. Results visualizations\n",
    "8. Model export\n",
    "9. Python and html generation\n",
    "\n",
    "#### Assumptions\n",
    "* Data is provided with a single csv file with an header representing the columns'names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DATA_FILE = 'data/example'\n",
    "INSTALL_LIBRARIES = True\n",
    "REMOVE_ROWS_WITH_INVALID_COLS = True #if False then a SimpleImputer will be used\n",
    "MATPLOT_STYLE = 'seaborn-dark-palette'\n",
    "TARGET_COLUMN = 'targetExample'\n",
    "#if different from None it represents the number of wanted features in the feature selection step\n",
    "NUM_FEATURES = 5\n",
    "MODEL_EXP_PATH = 'bestClassifier.joblib'\n",
    "OUTPUT_SCRIPT_NAME = 'modelPython.py'\n",
    "OUTPUT_HTML_NAME = 'model_report.html'\n",
    "MODEL_EXPORT = True\n",
    "REPORT_GEN = True\n",
    "\n",
    "columns_to_remove =['timestamp','data_2','id','data_3','timestamp_2']\n",
    "\n",
    "#not include the target in this list\n",
    "column_to_visualize = ['column1','column2','column3']\n",
    "\n",
    "column_names_and_types= {\n",
    "         'column1': 'datetime64',\n",
    "         'column2': 'float64',\n",
    "         'column3': 'float64'\n",
    "        }\n",
    "\n",
    "#this manage eventually data errors in the dataset using coerce\n",
    "numeric_features = ['column2','column3']\n",
    "datetime_features = ['column1']\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "#this will be used in step 5\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    #GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=30, max_features=0.6, n_jobs=-1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-Import of common libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INSTALL_LIBRARIES:\n",
    "    import sys\n",
    "    !conda install --yes --prefix {sys.prefix} matplotlib\n",
    "    !conda install --yes --prefix {sys.prefix} numpy\n",
    "    !conda install --yes --prefix {sys.prefix} pandas\n",
    "    !conda install --yes --prefix {sys.prefix} scikit-learn\n",
    "    !conda install --yes --prefix {sys.prefix} ipython\n",
    "    !conda install --yes --prefix {sys.prefix} seaborn\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn import metrics\n",
    "from IPython.display import display\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import json\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import pprint\n",
    "import heapq\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "plt.style.use(MATPLOT_STYLE)\n",
    "large = 22; med = 16; small = 12\n",
    "params = {'axes.titlesize': large,\n",
    "          'legend.fontsize': med,\n",
    "          'figure.figsize': (26, 20),\n",
    "          'axes.labelsize': med,\n",
    "          'axes.titlesize': med,\n",
    "          'xtick.labelsize': med,\n",
    "          'ytick.labelsize': med,\n",
    "          'figure.titlesize': large}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-Data ingestion & cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_input_df = pd.read_csv(INPUT_DATA_FILE, infer_datetime_format=True, index_col=False, skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here insert needed specific data cleaning and transformation steps\n",
    "\n",
    "raw_input_df['column1'] = raw_input_df['external_humidity'].str.rstrip('%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_input_df = raw_input_df.drop(columns=columns_to_remove)\n",
    "\n",
    "raw_input_df[numeric_features] = raw_input_df[numeric_features].apply(pd.to_numeric, errors='coerce')\n",
    "raw_input_df= raw_input_df.astype(column_names_and_types, copy=False, errors='ignore')\n",
    "raw_input_df[datetime_features] = raw_input_df[datetime_features].apply(pd.to_datetime, format='%Y/%m/%d %H:%M')\n",
    "\n",
    "if REMOVE_ROWS_WITH_INVALID_COLS:\n",
    "    raw_input_df = raw_input_df.dropna()\n",
    "else:\n",
    "    #TODO: simpleimpute numerical values\n",
    "    pass\n",
    "\n",
    "display(raw_input_df.head())\n",
    "display(raw_input_df.describe())\n",
    "display(raw_input_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-Data Analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = column_to_visualize\n",
    "column_to_visualize.append(TARGET_COLUMN)\n",
    "\n",
    "plt.figure(figsize=(20,15))\n",
    "sns.pairplot(raw_input_df[column_to_visualize].sample(frac=0.5), kind=\"reg\", hue=TARGET_COLUMN, corner=True, diag_kind=\"kde\", height=16)\n",
    "plt.suptitle('Pair Plot Features', size = 28);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15), dpi= 80)\n",
    "sns.heatmap(raw_input_df[column_to_visualize].corr(), xticklabels=raw_input_df[column_to_visualize].corr().columns, yticklabels=raw_input_df[column_to_visualize].corr().columns, cmap='RdYlGn', center=0, annot=True)\n",
    "\n",
    "# Decorations\n",
    "plt.title('Correlation matrix', fontsize=22)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_input_df[TARGET_COLUMN].plot(kind='hist', subplots=True, figsize=(8, 8))\n",
    "plt.title(\"Target distribution\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = input_features\n",
    "input_features.remove(TARGET_COLUMN)\n",
    "reduced = False\n",
    "if NUM_FEATURES and NUM_FEATURES <= len(input_features):\n",
    "    #feature_names = list(raw_input_df.columns.values)\n",
    "    reduced = True\n",
    "    # Create and fit selector\n",
    "    select_k_best_classifier = SelectKBest(f_classif, k=NUM_FEATURES)\n",
    "    fit_transofrmed_features = select_k_best_classifier.fit_transform(raw_input_df[input_features], raw_input_df[TARGET_COLUMN])\n",
    "    \n",
    "    mask = select_k_best_classifier.get_support() #list of booleans\n",
    "    new_features = [] # The list of your K best features\n",
    "\n",
    "    for bool, feature in zip(mask, input_features):\n",
    "        if bool:\n",
    "            new_features.append(feature)\n",
    "            \n",
    "    print(\"Selected features are: %s\" % new_features)\n",
    "    input_df_reduced = pd.DataFrame(fit_transofrmed_features, columns=new_features)\n",
    "    input_df_reduced[TARGET_COLUMN] = raw_input_df[TARGET_COLUMN].to_numpy()\n",
    "    display(input_df_reduced.head())\n",
    "    display(input_df_reduced.describe())\n",
    "    display(input_df_reduced.info())\n",
    "else:\n",
    "    input_df_reduced = raw_input_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-ML model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "# preprocess dataset, split into training and test part\n",
    "X = input_df_reduced.loc[:, input_df_reduced.columns != TARGET_COLUMN]\n",
    "y = input_df_reduced[TARGET_COLUMN]\n",
    "X = StandardScaler().fit_transform(X) #ATTENTION: for each prediction we need to fit_transform first\n",
    "X_train, X_validation, y_train, y_validation = \\\n",
    "    train_test_split(X, y, test_size=.3, random_state=42)\n",
    "X_validation, X_test, y_validation, y_test = \\\n",
    "    train_test_split(X_validation, y_validation, test_size=.2, random_state=42)\n",
    "\n",
    "#HERE MACROAVG_F1 IS USED, CHANGE IT IF YOU NEED\n",
    "indexBestClassifier = 0\n",
    "maxScore = 0\n",
    "actualIndex = 0\n",
    "\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    print(\"#\"*10)\n",
    "    print(\"Trying with classifier: {}\".format(clf))\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_validation, y_validation)\n",
    "    clf_report = classification_report(y_validation, clf.predict(X_validation), output_dict=True)\n",
    "    print(json.dumps(clf_report,sort_keys=True, indent=4))\n",
    "    score_to_use = float(clf_report[\"weighted avg\"][\"f1-score\"])\n",
    "    if score_to_use > maxScore:\n",
    "        maxScore = score_to_use\n",
    "        indexBestClassifier = actualIndex\n",
    "    actualIndex +=1\n",
    "    \n",
    "print(\"The best classifier is: {} with score {}\".format(classifiers[indexBestClassifier], maxScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-ML model tuning - to be modified manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_neighbors' : [3, 6, 8, 25, 66, 88],\n",
    "    'weights' : ['uniform', 'distance'],\n",
    "    'metric' : ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "param_to_be_varied_in_validation_curve = 'n_neighbors'\n",
    "param_range_valid_curve = [3, 6, 8, 25, 66, 88]\n",
    "\n",
    "clf_best = RandomizedSearchCV(classifiers[indexBestClassifier], params, n_iter = 15, scoring='f1_weighted', random_state=42).fit(X,y)\n",
    "#clf_best = GridSearchCV(classifiers[indexBestClassifier], params, scoring='f1_weighted').fit(X,y)\n",
    "best_estimator = clf_best.best_estimator_\n",
    "bestScore = clf_best.best_score_\n",
    "results = pd.DataFrame(clf_best.cv_results_)\n",
    "print(\"Results from hyperParams search: \")\n",
    "print(json.dumps(results.to_dict(),indent=4))\n",
    "print(\"Best classifier found: {} with score {}\".format(best_estimator,bestScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-Results visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a scatter using the first 2 most important features and colour in red the yellow \n",
    "y_pred = best_estimator.predict(X_test)\n",
    "print(\"Score: \",best_estimator.score(X_test,y_test))\n",
    "misclassified_examples = X_test[y_test != y_pred]\n",
    "print(\"Misclassified len: \",len(misclassified_examples))\n",
    "misclassified_examples = pd.DataFrame(misclassified_examples,columns=new_features)\n",
    "corrected_examples = X_test[y_test == y_pred]\n",
    "print(\"corrected_examples len: \",len(corrected_examples))\n",
    "corrected_examples = pd.DataFrame(corrected_examples,columns=new_features)\n",
    "if reduced:\n",
    "    list_scores = list(select_k_best_classifier.scores_)\n",
    "    print(\"list_scores: \",list_scores)\n",
    "    two_best_scores = heapq.nlargest(2, list_scores)\n",
    "    print(\"two_best_scores: \",two_best_scores)\n",
    "    best_feature_one = input_features[list_scores.index(two_best_scores[0])]\n",
    "    print(\"best_feature_one: \",best_feature_one)\n",
    "    best_feature_two = input_features[list_scores.index(two_best_scores[1])]\n",
    "    print(\"best_feature_two: \",best_feature_two)\n",
    "else:\n",
    "    best_feature_one = input_features[0]\n",
    "    best_feature_two = input_features[1]\n",
    "\n",
    "# Create Fig and gridspec\n",
    "fig = plt.figure(figsize=(16, 10), dpi= 80)\n",
    "grid = plt.GridSpec(4, 4, hspace=0.5, wspace=0.2)\n",
    "\n",
    "# Define the axes\n",
    "ax_main = fig.add_subplot(grid[:-1, :-1])\n",
    "ax_right = fig.add_subplot(grid[:-1, -1], xticklabels=[], yticklabels=[])\n",
    "ax_bottom = fig.add_subplot(grid[-1, 0:-1], xticklabels=[], yticklabels=[])\n",
    "\n",
    "\n",
    "# Scatterplot on main ax\n",
    "ax_main.scatter(corrected_examples[best_feature_one], corrected_examples[best_feature_two], label='correct',marker=\"s\", c='blue', alpha=.9, cmap=\"tab10\", edgecolors='black', linewidths=.5)\n",
    "ax_main.scatter(misclassified_examples[best_feature_one], misclassified_examples[best_feature_two], label='errors',marker=\"s\", c='yellow', alpha=.9, cmap=\"tab10\", edgecolors='red', linewidths=.5)\n",
    "\n",
    "X_validation_df = pd.DataFrame(X_validation,columns=new_features)\n",
    "\n",
    "# histogram on the right\n",
    "ax_bottom.hist(X_validation_df[best_feature_one], 40, histtype='stepfilled', orientation='vertical', color='olive')\n",
    "ax_bottom.invert_yaxis()\n",
    "\n",
    "# histogram in the bottom\n",
    "ax_right.hist(X_validation_df[best_feature_two], 40, histtype='stepfilled', orientation='horizontal', color='olive')\n",
    "\n",
    "# Decorations\n",
    "ax_main.set(title='Results', xlabel=best_feature_one, ylabel=best_feature_two)\n",
    "ax_main.title.set_fontsize(20)\n",
    "for item in ([ax_main.xaxis.label, ax_main.yaxis.label] + ax_main.get_xticklabels() + ax_main.get_yticklabels()):\n",
    "    item.set_fontsize(14)\n",
    "\n",
    "xlabels = ax_main.get_xticks().tolist()\n",
    "ax_main.set_xticklabels(xlabels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(y.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X_shuffled, y_shuffled = X[indices], y[indices]\n",
    "\n",
    "train_scores, valid_scores = validation_curve(best_estimator, X_shuffled, y_shuffled,\n",
    "                                              param_to_be_varied_in_validation_curve,\n",
    "                                              param_range_valid_curve,\n",
    "                                              cv=5)\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(valid_scores, axis=1)\n",
    "test_scores_std = np.std(valid_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve\")\n",
    "plt.xlabel(best_feature_one)\n",
    "plt.ylabel(best_feature_two)\n",
    "lw = 2\n",
    "plt.semilogx(param_range_valid_curve, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range_valid_curve, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range_valid_curve, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range_valid_curve, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, axes=None, ylim=None, cv=None,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate 3 plots: the test and training learning curve, the training\n",
    "    samples vs fit times curve, the fit times vs score curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    axes : array of 3 axes, optional (default=None)\n",
    "        Axes to use for plotting the curves.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 5-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - :term:`CV splitter`,\n",
    "          - An iterable yielding (train, test) splits as arrays of indices.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : int or None, optional (default=None)\n",
    "        Number of jobs to run in parallel.\n",
    "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
    "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
    "        for more details.\n",
    "\n",
    "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
    "        Relative or absolute numbers of training examples that will be used to\n",
    "        generate the learning curve. If the dtype is float, it is regarded as a\n",
    "        fraction of the maximum size of the training set (that is determined\n",
    "        by the selected validation method), i.e. it has to be within (0, 1].\n",
    "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
    "        Note that for classification the number of samples usually have to\n",
    "        be big enough to contain at least one sample from each class.\n",
    "        (default: np.linspace(0.1, 1.0, 5))\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        _, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "    axes[0].set_title(title)\n",
    "    axes[0].title.set_fontsize(20)\n",
    "    if ylim is not None:\n",
    "        axes[0].set_ylim(*ylim)\n",
    "    axes[0].set_xlabel(\"Training examples\")\n",
    "    axes[0].set_ylabel(\"Score\")\n",
    "\n",
    "    train_sizes, train_scores, test_scores, fit_times, _ = \\\n",
    "        learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,\n",
    "                       return_times=True)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    fit_times_mean = np.mean(fit_times, axis=1)\n",
    "    fit_times_std = np.std(fit_times, axis=1)\n",
    "\n",
    "    # Plot learning curve\n",
    "    axes[0].grid()\n",
    "    axes[0].fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                         color=\"r\")\n",
    "    axes[0].fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                         color=\"g\")\n",
    "    axes[0].plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "                 label=\"Training score\")\n",
    "    axes[0].plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "                 label=\"Cross-validation score\")\n",
    "    axes[0].legend(loc=\"best\")\n",
    "\n",
    "    # Plot n_samples vs fit_times\n",
    "    axes[1].grid()\n",
    "    axes[1].plot(train_sizes, fit_times_mean, 'o-')\n",
    "    axes[1].fill_between(train_sizes, fit_times_mean - fit_times_std,\n",
    "                         fit_times_mean + fit_times_std, alpha=0.1)\n",
    "    axes[1].set_xlabel(\"Training examples\")\n",
    "    axes[1].set_ylabel(\"fit_times\")\n",
    "    axes[1].set_title(\"Scalability of the model\")\n",
    "    axes[1].title.set_fontsize(20)\n",
    "\n",
    "    # Plot fit_time vs score\n",
    "    axes[2].grid()\n",
    "    axes[2].plot(fit_times_mean, test_scores_mean, 'o-')\n",
    "    axes[2].fill_between(fit_times_mean, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.1)\n",
    "    axes[2].set_xlabel(\"fit_times\")\n",
    "    axes[2].set_ylabel(\"Score\")\n",
    "    axes[2].set_title(\"Performance of the model\")\n",
    "    axes[2].title.set_fontsize(20)\n",
    "\n",
    "    return plt\n",
    "\n",
    "\n",
    "title = \"Learning Curves\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = best_estimator\n",
    "plot_learning_curve(estimator, title, X, y,cv=cv, n_jobs=-1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-Model export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODEL_EXPORT:\n",
    "    from joblib import dump, load\n",
    "    dump(best_estimator, MODEL_EXP_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9-Python and html generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "var kernel = IPython.notebook.kernel;\n",
    "var thename = window.document.getElementById(\"notebook_name\").innerHTML;\n",
    "var command = \"theNotebook = \" + \"'\"+thename+\"'\";\n",
    "kernel.execute(command);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPORT_GEN:\n",
    "    import nbformat\n",
    "    from nbconvert import PythonExporter\n",
    "    import os\n",
    "    import codecs\n",
    "    from IPython.display import Javascript\n",
    "    import time\n",
    "    from nbconvert import HTMLExporter\n",
    "\n",
    "\n",
    "    def convertNotebook(notebookPath, modulePath):\n",
    "\n",
    "      with open(notebookPath) as fh:\n",
    "        nb = nbformat.reads(fh.read(), nbformat.NO_CONVERT)\n",
    "\n",
    "      exporter = PythonExporter()\n",
    "      source, meta = exporter.from_notebook_node(nb)\n",
    "      with open(modulePath, 'w+') as fh:\n",
    "        fh.writelines(source)\n",
    "\n",
    "\n",
    "    def save_notebook():\n",
    "        display(\n",
    "            Javascript(\"IPython.notebook.save_notebook()\"),\n",
    "            include=['application/javascript']\n",
    "        )\n",
    "\n",
    "    def output_HTML(read_file, output_file):\n",
    "        exporter = HTMLExporter()\n",
    "        # read_file is '.ipynb', output_file is '.html'\n",
    "        output_notebook = nbformat.read(read_file, as_version=4)\n",
    "        output, resources = exporter.from_notebook_node(output_notebook)\n",
    "        codecs.open(output_file, 'w', encoding='utf-8').write(output)\n",
    "\n",
    "    nb_full_path = os.path.join(os.getcwd(), theNotebook)\n",
    "    convertNotebook(nb_full_path+\".ipynb\", OUTPUT_SCRIPT_NAME)\n",
    "\n",
    "    save_notebook()\n",
    "    time.sleep(3)\n",
    "    current_file = theNotebook+\".ipynb\"\n",
    "    output_HTML(current_file, OUTPUT_HTML_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
